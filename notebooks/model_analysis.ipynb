{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DyHuCoG Model Analysis\n",
    "\n",
    "This notebook provides in-depth analysis of the DyHuCoG model components and behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.models.dyhucog import DyHuCoG\n",
    "from src.models.lightgcn import LightGCN\n",
    "from src.models.ngcf import NGCF\n",
    "from src.data.dataset import RecommenderDataset\n",
    "from src.utils.graph_builder import GraphBuilder\n",
    "from config.model_config import get_model_config\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = RecommenderDataset(\n",
    "    name='ml-100k',\n",
    "    path='../data/',\n",
    "    test_size=0.2,\n",
    "    val_size=0.1\n",
    ")\n",
    "\n",
    "# Load configuration\n",
    "config = get_model_config('../config/config.yaml').to_dict()\n",
    "\n",
    "print(f\"Dataset loaded: {dataset.n_users} users, {dataset.n_items} items\")\n",
    "print(f\"Model config: latent_dim={config['model']['latent_dim']}, n_layers={config['model']['n_layers']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "dyhucog = DyHuCoG(\n",
    "    n_users=dataset.n_users,\n",
    "    n_items=dataset.n_items,\n",
    "    n_genres=dataset.n_genres,\n",
    "    config=config['model']\n",
    ").to(device)\n",
    "\n",
    "lightgcn = LightGCN(\n",
    "    n_users=dataset.n_users,\n",
    "    n_items=dataset.n_items,\n",
    "    latent_dim=config['model']['latent_dim'],\n",
    "    n_layers=config['model']['n_layers']\n",
    ").to(device)\n",
    "\n",
    "print(\"Models initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cooperative Game Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze DAE reconstruction\n",
    "from src.data.dataloader import get_dataloader\n",
    "\n",
    "# Get a batch of user data\n",
    "train_loader = get_dataloader(dataset, 'train', config)\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Get user interaction vectors\n",
    "user_items = batch['user_items'][:10].to(device)  # Take 10 users\n",
    "\n",
    "# Test DAE reconstruction\n",
    "dyhucog.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed = dyhucog.dae(user_items)\n",
    "\n",
    "# Visualize reconstruction\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Get top 20 items for visualization\n",
    "    original = user_items[i].cpu().numpy()[:20]\n",
    "    recon = reconstructed[i].cpu().numpy()[:20]\n",
    "    \n",
    "    x = np.arange(len(original))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, original, width, label='Original', alpha=0.7)\n",
    "    ax.bar(x + width/2, recon, width, label='Reconstructed', alpha=0.7)\n",
    "    \n",
    "    ax.set_title(f'User {i+1}')\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.legend()\n",
    "\n",
    "plt.suptitle('DAE Reconstruction Quality (First 20 Items)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Shapley values\n",
    "# Get Shapley values for sample users\n",
    "sample_users = [1, 10, 50, 100, 500]\n",
    "shapley_analysis = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user_id in sample_users:\n",
    "        user_items = dataset.train_mat[user_id].to(device)\n",
    "        if user_items.sum() > 0:\n",
    "            shapley_values = dyhucog.shapley_net(user_items.unsqueeze(0)).squeeze()\n",
    "            \n",
    "            # Get non-zero items and their Shapley values\n",
    "            item_indices = torch.where(user_items > 0)[0]\n",
    "            item_shapley = [(idx.item() + 1, shapley_values[idx].item()) \n",
    "                          for idx in item_indices]\n",
    "            \n",
    "            # Sort by Shapley value\n",
    "            item_shapley.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            shapley_analysis.append({\n",
    "                'user_id': user_id,\n",
    "                'n_items': len(item_indices),\n",
    "                'top_items': item_shapley[:5],\n",
    "                'mean_shapley': np.mean([s[1] for s in item_shapley]),\n",
    "                'std_shapley': np.std([s[1] for s in item_shapley])\n",
    "            })\n",
    "\n",
    "# Display analysis\n",
    "for analysis in shapley_analysis:\n",
    "    print(f\"\\nUser {analysis['user_id']} ({analysis['n_items']} items):\")\n",
    "    print(f\"  Mean Shapley value: {analysis['mean_shapley']:.4f} Â± {analysis['std_shapley']:.4f}\")\n",
    "    print(\"  Top 5 items by Shapley value:\")\n",
    "    for item_id, shapley in analysis['top_items']:\n",
    "        print(f\"    Item {item_id}: {shapley:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare graph structures\n",
    "# Build different graph types\n",
    "ui_adj, ui_nodes = GraphBuilder.build_user_item_graph(dataset)\n",
    "hyper_adj, hyper_nodes = GraphBuilder.build_hypergraph(dataset)\n",
    "\n",
    "# Normalize adjacency matrices\n",
    "ui_adj_norm = GraphBuilder.normalize_adj(ui_adj)\n",
    "hyper_adj_norm = GraphBuilder.normalize_adj(hyper_adj)\n",
    "\n",
    "print(\"Graph Statistics:\")\n",
    "print(f\"User-Item Graph: {ui_nodes} nodes, {ui_adj._nnz()} edges\")\n",
    "print(f\"Hypergraph: {hyper_nodes} nodes, {hyper_adj._nnz()} edges\")\n",
    "print(f\"\\nAdditional nodes in hypergraph: {hyper_nodes - ui_nodes} (genres)\")\n",
    "print(f\"Additional edges in hypergraph: {hyper_adj._nnz() - ui_adj._nnz()} (item-genre connections)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a small subgraph\n",
    "# Sample a small neighborhood for visualization\n",
    "sample_user = 1\n",
    "sample_items = dataset.train_mat[sample_user].nonzero()[0][:5].tolist()\n",
    "\n",
    "# Create NetworkX graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add user node\n",
    "G.add_node(f'U{sample_user}', node_type='user')\n",
    "\n",
    "# Add item nodes and edges\n",
    "for item_idx in sample_items:\n",
    "    item_id = item_idx.item() + 1\n",
    "    G.add_node(f'I{item_id}', node_type='item')\n",
    "    G.add_edge(f'U{sample_user}', f'I{item_id}')\n",
    "    \n",
    "    # Add genre nodes\n",
    "    if item_id in dataset.item_genres:\n",
    "        for genre_idx in dataset.item_genres[item_id]:\n",
    "            genre_name = dataset.genre_cols[genre_idx]\n",
    "            G.add_node(f'G{genre_name}', node_type='genre')\n",
    "            G.add_edge(f'I{item_id}', f'G{genre_name}')\n",
    "\n",
    "# Plot the subgraph\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "\n",
    "# Draw nodes by type\n",
    "user_nodes = [n for n, d in G.nodes(data=True) if d['node_type'] == 'user']\n",
    "item_nodes = [n for n, d in G.nodes(data=True) if d['node_type'] == 'item']\n",
    "genre_nodes = [n for n, d in G.nodes(data=True) if d['node_type'] == 'genre']\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=user_nodes, node_color='red', \n",
    "                      node_size=1000, node_shape='s', label='User')\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=item_nodes, node_color='lightblue',\n",
    "                      node_size=800, label='Items')\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=genre_nodes, node_color='lightgreen',\n",
    "                      node_size=600, node_shape='^', label='Genres')\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5)\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "plt.title(f'Hypergraph Structure Example (User {sample_user})', fontsize=14)\n",
    "plt.legend()\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedding Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare embeddings from different models\n",
    "# Build weighted graph for DyHuCoG\n",
    "edge_weights = dyhucog.compute_shapley_weights(dataset.train_mat.to(device))\n",
    "edge_index, edge_weight = GraphBuilder.get_edge_list(dataset, edge_weights)\n",
    "dyhucog.build_hypergraph(edge_index.to(device), edge_weight.to(device), dataset.item_genres)\n",
    "\n",
    "# Get embeddings\n",
    "with torch.no_grad():\n",
    "    # DyHuCoG embeddings\n",
    "    dyhucog_emb = dyhucog.forward()\n",
    "    dyhucog_user_emb = dyhucog_emb[:dataset.n_users]\n",
    "    dyhucog_item_emb = dyhucog_emb[dataset.n_users:dataset.n_users + dataset.n_items]\n",
    "    \n",
    "    # LightGCN embeddings\n",
    "    lightgcn_user_emb, lightgcn_item_emb = lightgcn.forward(ui_adj_norm.to(device))\n",
    "\n",
    "print(f\"DyHuCoG embeddings: User {dyhucog_user_emb.shape}, Item {dyhucog_item_emb.shape}\")\n",
    "print(f\"LightGCN embeddings: User {lightgcn_user_emb.shape}, Item {lightgcn_item_emb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embedding distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# User embedding norms\n",
    "dyhucog_user_norms = torch.norm(dyhucog_user_emb, dim=1).cpu().numpy()\n",
    "lightgcn_user_norms = torch.norm(lightgcn_user_emb, dim=1).cpu().numpy()\n",
    "\n",
    "axes[0, 0].hist(dyhucog_user_norms, bins=50, alpha=0.7, label='DyHuCoG', color='blue')\n",
    "axes[0, 0].hist(lightgcn_user_norms, bins=50, alpha=0.7, label='LightGCN', color='orange')\n",
    "axes[0, 0].set_xlabel('Embedding Norm')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('User Embedding Norm Distribution')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Item embedding norms\n",
    "dyhucog_item_norms = torch.norm(dyhucog_item_emb, dim=1).cpu().numpy()\n",
    "lightgcn_item_norms = torch.norm(lightgcn_item_emb, dim=1).cpu().numpy()\n",
    "\n",
    "axes[0, 1].hist(dyhucog_item_norms, bins=50, alpha=0.7, label='DyHuCoG', color='blue')\n",
    "axes[0, 1].hist(lightgcn_item_norms, bins=50, alpha=0.7, label='LightGCN', color='orange')\n",
    "axes[0, 1].set_xlabel('Embedding Norm')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].set_title('Item Embedding Norm Distribution')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Embedding similarity distribution (sample)\n",
    "sample_size = 100\n",
    "sample_indices = np.random.choice(dataset.n_users, sample_size, replace=False)\n",
    "\n",
    "# DyHuCoG similarities\n",
    "dyhucog_sample = dyhucog_user_emb[sample_indices]\n",
    "dyhucog_sim = torch.matmul(dyhucog_sample, dyhucog_sample.t()).cpu().numpy()\n",
    "dyhucog_sim_flat = dyhucog_sim[np.triu_indices(sample_size, k=1)]\n",
    "\n",
    "# LightGCN similarities\n",
    "lightgcn_sample = lightgcn_user_emb[sample_indices]\n",
    "lightgcn_sim = torch.matmul(lightgcn_sample, lightgcn_sample.t()).cpu().numpy()\n",
    "lightgcn_sim_flat = lightgcn_sim[np.triu_indices(sample_size, k=1)]\n",
    "\n",
    "axes[1, 0].hist(dyhucog_sim_flat, bins=50, alpha=0.7, label='DyHuCoG', color='blue')\n",
    "axes[1, 0].hist(lightgcn_sim_flat, bins=50, alpha=0.7, label='LightGCN', color='orange')\n",
    "axes[1, 0].set_xlabel('Cosine Similarity')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('User-User Similarity Distribution')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# t-SNE visualization (small sample)\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne_sample = 200\n",
    "tsne_indices = np.random.choice(dataset.n_users, tsne_sample, replace=False)\n",
    "\n",
    "# Combine embeddings\n",
    "combined_emb = np.vstack([\n",
    "    dyhucog_user_emb[tsne_indices].cpu().numpy(),\n",
    "    lightgcn_user_emb[tsne_indices].cpu().numpy()\n",
    "])\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(combined_emb)\n",
    "\n",
    "# Plot\n",
    "axes[1, 1].scatter(tsne_results[:tsne_sample, 0], tsne_results[:tsne_sample, 1],\n",
    "                  alpha=0.6, label='DyHuCoG', color='blue')\n",
    "axes[1, 1].scatter(tsne_results[tsne_sample:, 0], tsne_results[tsne_sample:, 1],\n",
    "                  alpha=0.6, label='LightGCN', color='orange')\n",
    "axes[1, 1].set_xlabel('t-SNE 1')\n",
    "axes[1, 1].set_ylabel('t-SNE 2')\n",
    "axes[1, 1].set_title('User Embedding t-SNE Visualization')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.suptitle('Embedding Analysis: DyHuCoG vs LightGCN', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Attention Mechanism Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze attention weights\n",
    "sample_users = torch.tensor([1, 10, 50, 100, 500], device=device)\n",
    "sample_items = torch.tensor([1, 10, 50, 100, 500], device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get embeddings\n",
    "    emb = dyhucog.forward()\n",
    "    user_emb = emb[sample_users - 1]\n",
    "    item_emb = emb[dataset.n_users + sample_items - 1]\n",
    "    \n",
    "    # Create all pairs\n",
    "    attention_weights = []\n",
    "    for i in range(len(sample_users)):\n",
    "        for j in range(len(sample_items)):\n",
    "            concat_emb = torch.cat([user_emb[i], item_emb[j]]).unsqueeze(0)\n",
    "            weight = dyhucog.attention(concat_emb).item()\n",
    "            attention_weights.append(weight)\n",
    "\n",
    "# Reshape to matrix\n",
    "attention_matrix = np.array(attention_weights).reshape(len(sample_users), len(sample_items))\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(attention_matrix, \n",
    "            xticklabels=[f'Item {i}' for i in sample_items.cpu()],\n",
    "            yticklabels=[f'User {u}' for u in sample_users.cpu()],\n",
    "            cmap='YlOrRd',\n",
    "            annot=True,\n",
    "            fmt='.3f',\n",
    "            cbar_kws={'label': 'Attention Weight'})\n",
    "plt.title('Attention Weights for User-Item Pairs')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Attention weight statistics:\")\n",
    "print(f\"  Mean: {np.mean(attention_weights):.4f}\")\n",
    "print(f\"  Std: {np.std(attention_weights):.4f}\")\n",
    "print(f\"  Min: {np.min(attention_weights):.4f}\")\n",
    "print(f\"  Max: {np.max(attention_weights):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Complexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Parameter counts\n",
    "dyhucog_params = count_parameters(dyhucog)\n",
    "lightgcn_params = count_parameters(lightgcn)\n",
    "\n",
    "# Break down DyHuCoG parameters\n",
    "embedding_params = dyhucog.embedding.weight.numel()\n",
    "dae_params = count_parameters(dyhucog.dae)\n",
    "shapley_params = count_parameters(dyhucog.shapley_net)\n",
    "attention_params = count_parameters(dyhucog.attention) if dyhucog.use_attention else 0\n",
    "\n",
    "# Create comparison\n",
    "param_data = {\n",
    "    'Model': ['DyHuCoG', 'LightGCN', 'DyHuCoG-Embedding', 'DyHuCoG-DAE', \n",
    "              'DyHuCoG-Shapley', 'DyHuCoG-Attention'],\n",
    "    'Parameters': [dyhucog_params, lightgcn_params, embedding_params, \n",
    "                  dae_params, shapley_params, attention_params]\n",
    "}\n",
    "\n",
    "param_df = pd.DataFrame(param_data)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['blue', 'orange', 'lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "plt.bar(param_df['Model'], param_df['Parameters'], color=colors)\n",
    "plt.xlabel('Model/Component')\n",
    "plt.ylabel('Number of Parameters')\n",
    "plt.title('Model Parameter Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add values on bars\n",
    "for i, v in enumerate(param_df['Parameters']):\n",
    "    plt.text(i, v + 1000, f'{v:,}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"Parameter Summary:\")\n",
    "print(f\"DyHuCoG total: {dyhucog_params:,}\")\n",
    "print(f\"LightGCN total: {lightgcn_params:,}\")\n",
    "print(f\"\\nDyHuCoG breakdown:\")\n",
    "print(f\"  Embeddings: {embedding_params:,} ({embedding_params/dyhucog_params*100:.1f}%)\")\n",
    "print(f\"  DAE: {dae_params:,} ({dae_params/dyhucog_params*100:.1f}%)\")\n",
    "print(f\"  Shapley Network: {shapley_params:,} ({shapley_params/dyhucog_params*100:.1f}%)\")\n",
    "print(f\"  Attention: {attention_params:,} ({attention_params/dyhucog_params*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Model Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save key findings\n",
    "analysis_results = {\n",
    "    'model_comparison': {\n",
    "        'dyhucog_params': dyhucog_params,\n",
    "        'lightgcn_params': lightgcn_params,\n",
    "        'parameter_overhead': f\"{(dyhucog_params - lightgcn_params) / lightgcn_params * 100:.1f}%\"\n",
    "    },\n",
    "    'graph_structure': {\n",
    "        'user_item_nodes': ui_nodes,\n",
    "        'hypergraph_nodes': hyper_nodes,\n",
    "        'genre_nodes': hyper_nodes - ui_nodes,\n",
    "        'edge_increase': f\"{(hyper_adj._nnz() - ui_adj._nnz()) / ui_adj._nnz() * 100:.1f}%\"\n",
    "    },\n",
    "    'embedding_analysis': {\n",
    "        'dyhucog_user_norm_mean': float(np.mean(dyhucog_user_norms)),\n",
    "        'lightgcn_user_norm_mean': float(np.mean(lightgcn_user_norms)),\n",
    "        'dyhucog_similarity_mean': float(np.mean(dyhucog_sim_flat)),\n",
    "        'lightgcn_similarity_mean': float(np.mean(lightgcn_sim_flat))\n",
    "    },\n",
    "    'attention_stats': {\n",
    "        'mean': float(np.mean(attention_weights)),\n",
    "        'std': float(np.std(attention_weights)),\n",
    "        'range': [float(np.min(attention_weights)), float(np.max(attention_weights))]\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../results/model_analysis.json', 'w') as f:\n",
    "    json.dump(analysis_results, f, indent=2)\n",
    "\n",
    "print(\"Model analysis completed and saved!\")\n",
    "print(\"\\nKey Findings:\")\n",
    "print(f\"- DyHuCoG has {analysis_results['model_comparison']['parameter_overhead']} more parameters than LightGCN\")\n",
    "print(f\"- Hypergraph adds {analysis_results['graph_structure']['genre_nodes']} genre nodes\")\n",
    "print(f\"- Edge count increases by {analysis_results['graph_structure']['edge_increase']}\")\n",
    "print(f\"- Attention weights range from {analysis_results['attention_stats']['range'][0]:.3f} to {analysis_results['attention_stats']['range'][1]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}